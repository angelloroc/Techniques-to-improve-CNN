{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data of Cats and Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = './data/archive.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('./data')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15060 Cat Images\n",
      "There are 15002 Dog Images\n"
     ]
    }
   ],
   "source": [
    "base_directory = './data/Animal Images/'\n",
    "source_dog = os.path.join(base_directory, 'dogs')\n",
    "source_cat = os.path.join(base_directory, 'cats')\n",
    "\n",
    "print(f\"There are {len(os.listdir(source_cat))} Cat Images\")\n",
    "print(f\"There are {len(os.listdir(source_dog))} Dog Images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new directory for training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('./cat-dogs/train/dogs')\n",
    "os.makedirs('./cat-dogs/train/cats')\n",
    "os.makedirs('./cat-dogs/validation/cats')\n",
    "os.makedirs('./cat-dogs/validation/dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "\n",
    "  lista = os.listdir(SOURCE_DIR)\n",
    "  lista_random = random.sample(lista,len(lista)) # input --> Type list\n",
    "\n",
    "  percentage = int(SPLIT_SIZE*len(lista_random)) # Puede darse el caso que no sea natural\n",
    "\n",
    "  data = [lista_random[i:i+percentage] for i in range(0,len(lista_random),percentage)] #forma más rápida pero falta el if\n",
    "  training_data = data[0]; # ['890.jpg', '12409.jpg', '9285.jpg', '8606.jpg']\n",
    "  test_data = data[1];\n",
    "\n",
    "\n",
    "  for i in training_data:\n",
    "    if (  os.path.getsize(SOURCE_DIR + i) != 0 ): # /tmp/PetImages/Cat/7364.jpg\n",
    "      shutil.copy(SOURCE_DIR + i, (TRAINING_DIR))\n",
    "    else:\n",
    "      print(i + \" is zero length, so ignoring.\")\n",
    "  for i in test_data:\n",
    "    if (os.path.getsize(SOURCE_DIR + i) !=  0):\n",
    "      shutil.copy(SOURCE_DIR + i, (VALIDATION_DIR)) # copyfile --> da error\n",
    "    else:\n",
    "      print(i + \" is zero length, so ignoring.\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_SOURCE_DIR = './data/Animal Images/cats/'\n",
    "DOG_SOURCE_DIR = './data/Animal Images/dogs/'\n",
    "\n",
    "CAT_TRAIN_DIR = './cat-dogs/train/cats/' \n",
    "DOG_TRAIN_DIR = './cat-dogs/train/dogs/'\n",
    "\n",
    "CAT_VAL_DIR = './cat-dogs/validation/cats/'\n",
    "DOG_VAL_DIR = './cat-dogs/validation/dogs/'\n",
    "\n",
    "SPLIT_SIZE = 0.9\n",
    "\n",
    "split_data(CAT_SOURCE_DIR, CAT_TRAIN_DIR, CAT_VAL_DIR, SPLIT_SIZE)\n",
    "split_data(DOG_SOURCE_DIR, DOG_TRAIN_DIR, DOG_VAL_DIR, SPLIT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13554 in training Cat Images\n",
      "There are 13501 in training Dog Images\n",
      "There are 1506 in validation Cat Images\n",
      "There are 1501 in validation Dog Images\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(os.listdir(CAT_TRAIN_DIR))} in training Cat Images\")\n",
    "print(f\"There are {len(os.listdir(DOG_TRAIN_DIR))} in training Dog Images\")\n",
    "print(f\"There are {len(os.listdir(CAT_VAL_DIR))} in validation Cat Images\")\n",
    "print(f\"There are {len(os.listdir(DOG_VAL_DIR))} in validation Dog Images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "      \n",
    "  train_data_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                                      rotation_range = 45,\n",
    "                                      shear_range = 0.2,\n",
    "                                      zoom_range = 0.2,\n",
    "                                      horizontal_flip = True,\n",
    "                                      width_shift_range = 0.2,\n",
    "                                      height_shift_range = 0.2,\n",
    "                                      fill_mode = \"nearest\")\n",
    "\n",
    " \n",
    "  train_generator = train_data_gen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=20,\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    " \n",
    "  validation_data_gen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "  validation_generator = validation_data_gen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=20,\n",
    "                                                                class_mode=\"binary\",\n",
    "                                                                target_size=(150, 150))\n",
    "  \n",
    "  return train_data_gen, validation_generator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN and Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\", input_shape = (150,150,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3),  activation ='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), # Agrupacion máx de 2x2\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Dropout(0.2), # Agregamos la probabilidad de que se apaguen aleatoriamente para que los pesos no sean disparejos\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'), # 512 neuronas\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # 1 output\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer = \"rmsprop\",\n",
    "              loss = \"categorical_crossentropy\", # cambia cuando solo son 2 clases\n",
    "              metrics = ['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(TRAIN_GEN,\n",
    "                    epochs = 12,\n",
    "                    verbose = 1,\n",
    "                    validation_data = VAL_GEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.utils as image\n",
    "\n",
    "archivo = files.upload()\n",
    "index = 0\n",
    "\n",
    "mayor = 0.\n",
    "for x in archivo.keys():\n",
    "  path = \"/content/\"+ x\n",
    "  img = image.load_img(path, target_size = (90,90))\n",
    "  \n",
    "  y = image.img_to_array(img)\n",
    "  y /= 255\n",
    "  y = np.expand_dims(y, axis=0)\n",
    "  images = np.vstack([y])\n",
    "\n",
    "  classes = model.predict(images, batch_size = 10)\n",
    "  print(classes[0])\n",
    "  for count,value in enumerate(classes[0]):\n",
    "    if value > mayor:\n",
    "      mayor = value\n",
    "      index = count\n",
    "  print(x + \"is a \" + str(index))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphics Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc,val_acc,loss,val_loss = history.history[\"accuracy\"],history.history[\"val_accuracy\"],history.history[\"loss\"],history.history[\"val_loss\"]\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs,acc, \"r\", \"Training Accuracy\")\n",
    "plt.plot(epochs,val_acc,\"b\",\"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs,loss,\"r\", \"Training Loss\")\n",
    "plt.plot(epochs,val_loss,\"b\", \"Validation Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6089aca65f867c8fb1e08b5b4f77829eb7c070fbe653f15230deda5bc54caea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
